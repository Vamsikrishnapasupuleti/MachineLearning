{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2afZ5F4oTiQe",
        "outputId": "fa971884-34ba-448c-bdbb-669a96d86514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADrPoTzzk3ZT",
        "outputId": "6a6cbd0d-20d0-4eab-c1d7-18221136a8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.4.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 40 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 86 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.4.0\n",
            "Collecting tune-sklearn\n",
            "  Downloading tune_sklearn-0.4.2-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tune-sklearn) (1.4.1)\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.7 MB 138 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (3.6.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (3.13)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (3.17.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (21.4.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (4.3.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (1.3.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (0.8.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune-sklearn) (2.23.0)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]->tune-sklearn) (1.15.0)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune-sklearn) (3.10.0.2)\n",
            "Collecting async-timeout>=4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune-sklearn) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune-sklearn) (4.11.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]->tune-sklearn) (1.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]->tune-sklearn) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]->tune-sklearn) (3.0.7)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->tune-sklearn) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->tune-sklearn) (0.18.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]->tune-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]->tune-sklearn) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune-sklearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune-sklearn) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune-sklearn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune-sklearn) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune-sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune-sklearn) (3.1.0)\n",
            "Installing collected packages: deprecated, async-timeout, redis, grpcio, tensorboardX, ray, tune-sklearn\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed async-timeout-4.0.2 deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.2.2 tensorboardX-2.5 tune-sklearn-0.4.2\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.21.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.6.3)\n",
            "Collecting hpbandster\n",
            "  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 93 kB/s \n",
            "\u001b[?25hCollecting Pyro4\n",
            "  Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting serpent\n",
            "  Downloading serpent-1.40-py3-none-any.whl (9.6 kB)\n",
            "Collecting ConfigSpace\n",
            "  Downloading ConfigSpace-0.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.21.5)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from hpbandster) (0.10.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.4.1)\n",
            "Collecting netifaces\n",
            "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace->hpbandster) (0.29.28)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace->hpbandster) (3.0.7)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->hpbandster) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->hpbandster) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.0->statsmodels->hpbandster) (1.15.0)\n",
            "Building wheels for collected packages: hpbandster\n",
            "  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=80006 sha256=81caf966b220d204ccd953f6e0b6b69d2140d0e11296f6473c55528afef467b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/88/fc/61ab6b9f386a386839668631c39a6dc3c2fb0ec7000d552faa\n",
            "Successfully built hpbandster\n",
            "Installing collected packages: serpent, Pyro4, netifaces, ConfigSpace, hpbandster\n",
            "Successfully installed ConfigSpace-0.5.0 Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.40\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders\n",
        "!pip install tune-sklearn\n",
        "!pip install scikit-optimize\n",
        "!pip install hyperopt\n",
        "!pip install hpbandster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pjgjMEQTpsb",
        "outputId": "9253660c-0ca4-4fbb-a2a2-a344e4727023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time \n",
        "import math\n",
        "import multiprocessing\n",
        "\n",
        "\n",
        "#for text pre-processing\n",
        "import re, string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# tune-sklearn\n",
        "from tune_sklearn import TuneGridSearchCV, TuneSearchCV\n",
        "\n",
        "\n",
        "# save model\n",
        "from joblib import dump, load\n",
        "\n",
        "# XGB \n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#for word embedding\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "# for categorical encoding\n",
        "import category_encoders as ce\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZxEZkNUDMh",
        "outputId": "be9ec079-7889-4113-c36b-4f9d4d962f19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27480, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Load Data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Project_ML/train.csv').dropna()\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WjvHb5iUHva",
        "outputId": "c3f47d93-e66e-4ddf-c66d-5fc1cc685db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "textID           0\n",
              "text             0\n",
              "selected_text    0\n",
              "sentiment        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "XSVfYUorUHsC",
        "outputId": "c787178c-ede5-4219-ee20-811aff0cb7e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.109881146585877\n",
            "13.473203958360108\n",
            "12.343887739498067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           textID                                               text  \\\n",
              "0      cb774db0d1                I`d have responded, if I were going   \n",
              "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2      088c60f138                          my boss is bullying me...   \n",
              "3      9642c003ef                     what interview! leave me alone   \n",
              "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "...           ...                                                ...   \n",
              "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
              "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
              "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
              "27479  ed167662a5                         But it was worth it  ****.   \n",
              "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
              "\n",
              "                                           selected_text sentiment  word_count  \n",
              "0                    I`d have responded, if I were going   neutral           7  \n",
              "1                                               Sooo SAD  negative          10  \n",
              "2                                            bullying me  negative           5  \n",
              "3                                         leave me alone  negative           5  \n",
              "4                                          Sons of ****,  negative          14  \n",
              "...                                                  ...       ...         ...  \n",
              "27476                                             d lost  negative          16  \n",
              "27477                                      , don`t force  negative          23  \n",
              "27478                          Yay good for both of you.  positive          22  \n",
              "27479                         But it was worth it  ****.  positive           6  \n",
              "27480  All this flirting going on - The ATG smiles. Y...   neutral          11  \n",
              "\n",
              "[27480 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28e69928-f4bd-4a28-b36c-b96864cc2374\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27476</th>\n",
              "      <td>4eac33d1c0</td>\n",
              "      <td>wish we could come see u on Denver  husband l...</td>\n",
              "      <td>d lost</td>\n",
              "      <td>negative</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27477</th>\n",
              "      <td>4f4c4fc327</td>\n",
              "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
              "      <td>, don`t force</td>\n",
              "      <td>negative</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27478</th>\n",
              "      <td>f67aae2310</td>\n",
              "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
              "      <td>Yay good for both of you.</td>\n",
              "      <td>positive</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27479</th>\n",
              "      <td>ed167662a5</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>positive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27480</th>\n",
              "      <td>6f7127d9d7</td>\n",
              "      <td>All this flirting going on - The ATG smiles...</td>\n",
              "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27480 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28e69928-f4bd-4a28-b36c-b96864cc2374')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28e69928-f4bd-4a28-b36c-b96864cc2374 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28e69928-f4bd-4a28-b36c-b96864cc2374');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df['word_count'] = train_df['text'].apply(lambda x: len(str(x).split()))\n",
        "print(train_df[train_df['sentiment']== 'positive']['word_count'].mean()) #Positive tweets\n",
        "print(train_df[train_df['sentiment']== 'negative']['word_count'].mean()) #Negative tweets\n",
        "print(train_df[train_df['sentiment']== 'neutral']['word_count'].mean()) #Neutral tweets\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "qPFgWTiOUHpj",
        "outputId": "ab4a43fb-c106-4e2f-fea7-f7db5f41696d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# PLOTTING WORD-COUNT\n",
        "fig,(ax1, ax2, ax3)=plt.subplots(1,3,figsize=(10,4))\n",
        "train_words=train_df[train_df['sentiment']=='positive']['word_count']\n",
        "ax1.hist(train_words,color='red')\n",
        "ax1.set_title('Positive tweets')\n",
        "train_words=train_df[train_df['sentiment']=='neutral']['word_count']\n",
        "ax3.hist(train_words,color='blue')\n",
        "ax3.set_title('Neutral tweets')\n",
        "train_words=train_df[train_df['sentiment']=='negative']['word_count']\n",
        "ax2.hist(train_words,color='green')\n",
        "ax2.set_title('Negative tweets')\n",
        "fig.suptitle('Words per tweet')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1e-B6blUHm-",
        "outputId": "b7dec037-8966-4bcd-f9dd-886284578ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70.41913306921464\n",
            "70.4881120678576\n",
            "65.20680039579022\n"
          ]
        }
      ],
      "source": [
        "# CHARACTER-COUNT\n",
        "train_df['char_count'] = train_df['text'].apply(lambda x: len(str(x)))\n",
        "print(train_df[train_df['sentiment']== 'positive']['char_count'].mean()) #Positive tweets\n",
        "print(train_df[train_df['sentiment']== 'negative']['char_count'].mean()) #Negative tweets\n",
        "print(train_df[train_df['sentiment']== 'neutral']['char_count'].mean()) #Neutral tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD2aUocRaaam"
      },
      "outputs": [],
      "source": [
        "#convert to lowercase, strip and remove extra spaces\n",
        "def preprocess(text):\n",
        "    text = text.lower() \n",
        "    text=text.strip()  \n",
        "    #text=re.compile('<.*?>').sub('', text) # remove any character enclosed in '<XXXXX>'\n",
        "    #text = re.compile('[%s]' % re.escape(string.punctuation)).sub('', text)  # remove punctuations\n",
        "    #text = re.sub('[^\\w\\s*]', '', text)  # remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s\\*\\']+', '', text) # remove punctuations\n",
        "    text = re.sub(r\"http\\S+\", \"\", text) # remove urls\n",
        "    #text = re.sub(r'\\[[0-9]*\\]','',text)  # remove digits\n",
        "    #text=re.sub(r'[^\\w\\s*]', '', str(text).lower().strip()) # remove non-word and whitespace\n",
        "    #text = re.sub(r'\\d','',text) # remove all digits\n",
        "    #text = re.sub(r'\\s+',' ',text) # remove all whitespaces\n",
        "    return text\n",
        "\n",
        "def find_indexes(str1_tokens, str2_tokens, sentiment):\n",
        "  #print(str1_tokens,'\\n',str2_tokens,'\\n', sentiment)\n",
        "  start= 0\n",
        "  end = 0\n",
        "  found = False\n",
        "  start_token = str2_tokens[0]\n",
        "  end_token = str2_tokens[len(str2_tokens)-1]\n",
        "  if sentiment == 'neutral':\n",
        "    end = len(str1_tokens)\n",
        "    found = True\n",
        "  else:\n",
        "    for idx_start, token in enumerate(str1_tokens):\n",
        "      if token == start_token:\n",
        "        start = idx_start\n",
        "        found = True\n",
        "        end = start + len(str2_tokens)\n",
        "        break\n",
        "  if start == end and found == True:\n",
        "    end = end+1     \n",
        "  elif found == False :\n",
        "    start = -1\n",
        "    end = -1\n",
        "  else:\n",
        "    start = start  \n",
        "    end = end\n",
        "  return start, end\n",
        "\n",
        "\n",
        "def finalpreprocess(string):\n",
        "    return preprocess(string)\n",
        "\n",
        "def sent_embeddings(sentence, model):\n",
        "  sent_vector = model.infer_vector(sentence)\n",
        "  return sent_vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDqiot0SUHOn"
      },
      "outputs": [],
      "source": [
        "train_df['clean_text'] = train_df['text'].apply(lambda x: finalpreprocess(x))\n",
        "train_df['clean_sel_text'] = train_df['selected_text'].apply(lambda x: finalpreprocess(x))\n",
        "train_df['clean_text_tokens']=[nltk.word_tokenize(i) for i in train_df['clean_text']]\n",
        "train_df['clean_sel_text_tokens']=[nltk.word_tokenize(i) for i in train_df['clean_sel_text']]\n",
        "train_df['cl_sel_length'] = train_df.clean_sel_text_tokens.str.len()\n",
        "train_df['cl_length'] = train_df.clean_text_tokens.str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuRidKofo_eZ"
      },
      "outputs": [],
      "source": [
        "# drop columns with empty text after preprocessing\n",
        "train_df = train_df.drop(train_df[train_df.cl_sel_length == 0].index)\n",
        "train_df = train_df.drop(train_df[train_df.cl_length == 0].index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP_LO6Essc63",
        "outputId": "e0d212c8-5353-46e3-f3d1-dbcd98650470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27479, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8KcvCMSg-8R"
      },
      "outputs": [],
      "source": [
        "# get start and end index of selected text tokens from original text tokens\n",
        "idx_list = train_df.apply(lambda x: find_indexes(x.clean_text_tokens, x.clean_sel_text_tokens, x.sentiment), axis=1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sycaiW8KrURO"
      },
      "outputs": [],
      "source": [
        "# unzip tuples and add to dataframe\n",
        "start_idx , end_idx = zip(*idx_list) \n",
        "train_df['start_idx']  = pd.Series(start_idx)\n",
        "train_df['end_idx']  = pd.Series(end_idx)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "# remove all columns where start and end indices are -1\n",
        "train_df = train_df.drop(train_df[train_df['start_idx'] == -1 ].index)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df['start_idx'] == -1][['clean_text_tokens', 'sentiment', 'selected_text', 'clean_sel_text_tokens', 'start_idx', 'end_idx']]\n",
        "train_df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJegOFVTqFt2",
        "outputId": "45b79906-8e48-45a7-e833-16433f62135b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26254, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xyLQfGzcUDQ"
      },
      "outputs": [],
      "source": [
        "PATH = f'/content/drive/MyDrive/Project_ML/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TaggedWikiDocument(object):\n",
        "    def __init__(self, wiki):\n",
        "        self.wiki = wiki\n",
        "        self.wiki.metadata = True\n",
        "    def __iter__(self):\n",
        "        for content, (page_id, title) in self.wiki.get_texts():\n",
        "            yield TaggedDocument([c for c in content], [title])"
      ],
      "metadata": {
        "id": "hMhw9EHkjNxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPhUNOMkYO4g"
      },
      "outputs": [],
      "source": [
        "# https://markroxor.github.io/gensim/static/notebooks/doc2vec-wikipedia.html\n",
        "# https://radimrehurek.com/gensim/corpora/wikicorpus.html\n",
        "# enwiki-latest-pages-articles.xml.bz2\n",
        "path_to_wiki_dump = datapath(\"enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2\")\n",
        "wiki = WikiCorpus(path_to_wiki_dump)\n",
        "documents = TaggedWikiDocument(wiki)\n",
        "#tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(train_df['clean_text']+ train_df['clean_sel_text'])]\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "\n",
        "# build Doc2Vec model\n",
        "# https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\n",
        "\n",
        "max_epochs = 100\n",
        "vec_size = 100\n",
        "alpha = 0.025\n",
        "\n",
        "model = Doc2Vec(vector_size=vec_size, dm=0, dbow_words=1, window=8, min_count=19, workers=cores, alpha=alpha, min_alpha=0.00025)\n",
        "#Doc2Vec(vector_size=vec_size, alpha=alpha, min_alpha=0.00025, min_count=1, dm =0) # dm=1 preserves order of words in a sentence (distributed memory) \n",
        "                                                                                          # d=0 (distributed BOW) which doesn't consider order of words in sentence\n",
        "model.build_vocab(documents)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "model.save(PATH+\"d2v.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOwFZj73Z81m"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "modeld2v= Doc2Vec.load(PATH+\"d2v.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzdGm9R4e3JC"
      },
      "outputs": [],
      "source": [
        "# converting text to numerical data using Doc3vec\n",
        "train_df['clean_text_embeds'] =  train_df.apply(lambda x: sent_embeddings(x.clean_text_tokens, modeld2v), axis=1)\n",
        "#clean_text_embeds =  train_df.apply(lambda x: sent_embeddings(x.clean_text_tokens, modeld2v), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW8kqcTEJK-_"
      },
      "outputs": [],
      "source": [
        "train_final_df = pd.DataFrame(train_df['clean_text_embeds'].tolist())\n",
        "train_df = pd.concat([train_df, train_final_df], axis=1)\n",
        "\n",
        "#train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdTcDQZMlzov"
      },
      "outputs": [],
      "source": [
        "# encode sentiment variable\n",
        "# https://contrib.scikit-learn.org/category_encoders/binary.html\n",
        "train_df['sentiment_en'] = train_df['sentiment']\n",
        "binary_encoder= ce.BinaryEncoder(cols=['sentiment_en'],return_df=True)\n",
        "train_df=binary_encoder.fit_transform(train_df) \n",
        "\n",
        "# inverse transform\n",
        "#train_df = binary_encoder.inverse_transform(train_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-cAj2GZu4DX",
        "outputId": "3ca05d6a-3ef3-42dc-e142-cc4e62caa7f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25068, 118)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# drop na values from final df\n",
        "train_df = train_df.dropna()\n",
        "#train_df = train_df.drop('index', axis=1)\n",
        "#train_df.isna().any()\n",
        "#train_df.head()\n",
        "train_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lHo_K5sKh13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2ab260-279d-4382-87fd-0d0c408d031b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ],
      "source": [
        "# prepare data for training.\n",
        "train_final_df['sentiment_en_0'] = train_df['sentiment_en_0']\n",
        "train_final_df['sentiment_en_1'] = train_df['sentiment_en_1']\n",
        "train_final_df['start_idx'] = train_df['start_idx']\n",
        "train_final_df['end_idx'] = train_df['end_idx']\n",
        "train_final_df['clean_text_tokens'] = train_df['clean_text_tokens']\n",
        "train_final_df['sentiment'] = train_df['sentiment']\n",
        "\n",
        "\n",
        "# drop na rows from final df\n",
        "train_final_df = train_final_df.dropna()\n",
        "train_final_df[['start_idx', 'end_idx', 'sentiment_en_0', 'sentiment_en_1']] = train_final_df[['start_idx','end_idx', 'sentiment_en_0', 'sentiment_en_1']].astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI0siWQcLSYY",
        "outputId": "208707cd-574f-4ce2-8519-36f918aa425c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25068, 118)\n"
          ]
        }
      ],
      "source": [
        "train_df[train_df['end_idx']==train_df['start_idx']+1][['clean_text_tokens', 'sentiment', 'selected_text', 'start_idx', 'end_idx']].head()\n",
        "#print(train_final_df.columns)\n",
        "#print(train_final_df.isna().sum())\n",
        "print(train_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJpkBSENahoO"
      },
      "outputs": [],
      "source": [
        "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
        "#X_train, X_test, y_train, y_test = train_test_split(train_df[[\"clean_text\", 'sentiment_en']],train_df[\"clean_sel_text\"],test_size=0.2,shuffle=True)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(train_df[[\"clean_text_embeds\", 'sentiment_en_0', 'sentiment_en_0']].values ,train_df[['start_idx', 'end_idx']].values, test_size=0.2, shuffle=True)\n",
        "X = train_final_df.drop(['start_idx', 'end_idx'], axis=1)\n",
        "y = train_final_df[['start_idx', 'end_idx']].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI_x8LlyZ37c"
      },
      "outputs": [],
      "source": [
        "#building Word2Vec model\n",
        "class EmbedVector():\n",
        "  def __init__(self, model_w2v):\n",
        "    self.model_w2v = model_w2v\n",
        "    self.dim = len(next(iter(model_w2v.values())))\n",
        "  def transform(self, X):\n",
        "    return np.array([np.mean([self.model_w2v[w] for w in words if w in self.model_w2v] or [np.zeros(self.dim)], axis=0) for words in X ])\n",
        "\n",
        "# tokenize sentences\n",
        "X_train_tokens= [nltk.word_tokenize(i) for i in X_train]  \n",
        "X_test_tokens= [nltk.word_tokenize(i) for i in X_test]\n",
        "\n",
        "model_w2v = Word2Vec(train_df['clean_text_tokens']+ train_df['clean_sel_text_tokens'])     \n",
        "w2v = dict(zip(model_w2v.wv.index2word, model_w2v.wv.vectors)) \n",
        "modelw = EmbedVector(w2v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j56iT-2aYw2"
      },
      "outputs": [],
      "source": [
        "# converting text to numerical data using Word2Vec\n",
        "X_train_vect_w2v = modelw.transform(X_train_tokens)\n",
        "X_val_vect_w2v = modelw.transform(X_test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7FCnr8NSZzX"
      },
      "outputs": [],
      "source": [
        "# Prepare final values for X (train & test)\n",
        "X_train_final = X_train.drop(['clean_text_tokens', 'sentiment'], axis=1).values\n",
        "X_test_final = X_test.drop(['clean_text_tokens', 'sentiment'], axis=1).values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/5x-faster-scikit-learn-parameter-tuning-in-5-lines-of-code-be6bdd21833c\n",
        "# https://docs.ray.io/en/latest/tune/api_docs/sklearn.html\n",
        "def build_search_model(param_grid, model, X_train, y_train, n_splits=3,  refit=True, verbose=False):\n",
        "  mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
        "  clf = TuneSearchCV(estimator=model, n_jobs=-1, verbose=verbose, param_distributions=param_grid, scoring=mse, cv=n_splits, refit=refit, search_optimization='hyperopt', early_stopping=False, max_iters=10) # 'hyperopt', 'bohb', 'random', 'bayesian'\n",
        "  #clf = TuneGridSearchCV(estimator=model, n_jobs=-1, verbose=verbose, param_grid=param_grid, scoring=mse, cv=n_splits, refit=refit, early_stopping=False, max_iters=10)\n",
        "  clf = clf.fit(X_train, y_train, early_stopping_round=6) \n",
        "  return clf"
      ],
      "metadata": {
        "id": "yOf_q1n4JU0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define param_grid\n",
        "xgb_param_grid = {\n",
        "    'estimator__max_depth': [10, 11, 12],\n",
        "    'estimator__n_estimators': [200, 500, 1000],\n",
        "    'estimator__learning_rate': [0.1, 0.01, 0.001, 0.004],\n",
        "    'estimator__random_state': [1],\n",
        "    'estimator__subsample':[0.7, 0.8, 0.5, 0.6]\n",
        "    #'estimator__tree_method':['gpu_hist']\n",
        "  }"
      ],
      "metadata": {
        "id": "Ws6mCFImJ2Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "CXLpxvZgv8uj",
        "outputId": "8b9a349e-118e-4161-c183-bb18a17eb440"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-04-05 02:25:41 (running for 02:39:34.65)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/6.66 GiB heap, 0.0/3.33 GiB objects<br>Result logdir: /root/ray_results/_Trainable_2022-04-04_23-46-01<br>Number of trials: 10/10 (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-05 02:25:41,944\tINFO tune.py:610 -- Total run time: 9580.76 seconds (9574.64 seconds for the tuning loop).\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 02:51:48\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', n_jobs=-1, nthread=4))\n",
        "start_time = time.time()\n",
        "clf = build_search_model(xgb_param_grid, model, X_train_final, y_train, verbose=True)\n",
        "seconds = time.time() - start_time\n",
        "print('Time Taken:', time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))\n",
        "xgb_estimator = clf.best_estimator_\n",
        "# save model\n",
        "dump(xgb_estimator, PATH+'xgb.joblib') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved model\n",
        "xgb_estimator = load(PATH+'xgb.joblib') \n",
        "\n",
        "y_hat = xgb_estimator.predict(X_test_final)\n",
        "#print(y_test)\n",
        "#print(y_hat)"
      ],
      "metadata": {
        "id": "U2SsDM7AlotW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZqtdDc5v8rN",
        "outputId": "500884a0-b43e-45ad-eb8b-b5fe3e40869f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Square Error:\n",
            "\n",
            "5.776564729417875\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(y_test, y_hat) \n",
        "rmse = math.sqrt(mse)\n",
        "print(\"Root Mean Square Error:\\n\")\n",
        "print(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test['clean_text_tokens'].reset_index(drop=True).tolist()"
      ],
      "metadata": {
        "id": "8vaJ6Jvclxsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DDdD-Abiv8oH",
        "outputId": "d85f601b-157b-4484-f72b-240e09a8dc4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      start  end  pred_start  pred_end  \\\n",
              "0         0   11           2         9   \n",
              "1         0   13           1         9   \n",
              "2         0   11           2         9   \n",
              "3         0    6           2         8   \n",
              "4         0   11           2         9   \n",
              "...     ...  ...         ...       ...   \n",
              "5009     11   24           2         9   \n",
              "5010      2    5           2         9   \n",
              "5011      2    3           2         8   \n",
              "5012      4    6           2         9   \n",
              "5013      2    3           2         9   \n",
              "\n",
              "                                      clean_text_tokens sentiment  \n",
              "0     [i, have, had, the, worst, headache, ever, in,...  negative  \n",
              "1     [had, a, really, weird, night, last, night, an...  negative  \n",
              "2     [you, should, enter, the, giveaway, then, who,...   neutral  \n",
              "3     [u, mean, vip, this, time, coz, of, the, kbs, ...   neutral  \n",
              "4                 [has, finally, found, her, new, flat]   neutral  \n",
              "...                                                 ...       ...  \n",
              "5009  [seeing, the, gf, 5, days, in, a, row, for, a,...  positive  \n",
              "5010  [mom, just, woke, me, up, and, i, am, so, mad,...  negative  \n",
              "5011  [she, could, spend, the, rest, of, the, night,...  positive  \n",
              "5012                   [moving, today, im, so, excited]  positive  \n",
              "5013  [epic, writing, fail, ew, going, to, try, and,...  negative  \n",
              "\n",
              "[5014 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-328819ce-6f97-42e1-a9b5-43d05b3268cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>pred_start</th>\n",
              "      <th>pred_end</th>\n",
              "      <th>clean_text_tokens</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[i, have, had, the, worst, headache, ever, in,...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>[had, a, really, weird, night, last, night, an...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[you, should, enter, the, giveaway, then, who,...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>[u, mean, vip, this, time, coz, of, the, kbs, ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[has, finally, found, her, new, flat]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5009</th>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[seeing, the, gf, 5, days, in, a, row, for, a,...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[mom, just, woke, me, up, and, i, am, so, mad,...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5011</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>[she, could, spend, the, rest, of, the, night,...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5012</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[moving, today, im, so, excited]</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5013</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>[epic, writing, fail, ew, going, to, try, and,...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5014 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-328819ce-6f97-42e1-a9b5-43d05b3268cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-328819ce-6f97-42e1-a9b5-43d05b3268cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-328819ce-6f97-42e1-a9b5-43d05b3268cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "df_pred = pd.DataFrame(y_hat, columns = ['pred_start','pred_end']).astype(int)\n",
        "df_actual = pd.DataFrame(y_test, columns = ['start','end']).astype(int)\n",
        "s = pd.Series(X_test['clean_text_tokens'])\n",
        "df_toks = pd.DataFrame(pd.Series(X_test['clean_text_tokens'].reset_index(drop=True).tolist()), columns=['clean_text_tokens']).astype(object)\n",
        "df_sent = pd.DataFrame(pd.Series(X_test['sentiment'].reset_index(drop=True).tolist()), columns=['sentiment']).astype(object)\n",
        "list = [df_actual, df_pred, df_toks, df_sent]\n",
        "df_final = pd.concat(list, axis=1)\n",
        "# reset index\n",
        "#df_final = df_final.reset_index(drop=True)\n",
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_final['original_text_tokens'] = X_test['clean_text_tokens']\n",
        "df_final.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLUnb_6oFIhe",
        "outputId": "d8a8515e-cc06-4f3a-d2bd-d955879a9f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "start                0\n",
              "end                  0\n",
              "pred_start           0\n",
              "pred_end             0\n",
              "clean_text_tokens    0\n",
              "sentiment            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz799ycwCLkE"
      },
      "outputs": [],
      "source": [
        "def get_sel_text_from_index(start, end, original_tokens, sentiment):\n",
        "  sel_text = ''\n",
        "  if sentiment == 'neutral':\n",
        "    sel_text_tokens = original_tokens\n",
        "  else:\n",
        "    sel_text_tokens = original_tokens[start:end]  \n",
        "    \n",
        "  sel_text = \" \".join(sel_text_tokens)\n",
        "  return sel_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1GQJV6wETRw"
      },
      "outputs": [],
      "source": [
        "df_final['pred_sel_text'] = df_final.apply(lambda x: get_sel_text_from_index(x.pred_start, x.pred_end, x.clean_text_tokens, x.sentiment), axis=1).tolist()\n",
        "df_final['act_sel_text'] = df_final.apply(lambda x: get_sel_text_from_index(x.start, x.end, x.clean_text_tokens, x.sentiment), axis=1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWbPNACyGQzY"
      },
      "outputs": [],
      "source": [
        "# Metric Jaccard score\n",
        "\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    if (len(a)==0) & (len(b)==0): return 0.5\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xoba64qxGeGm"
      },
      "outputs": [],
      "source": [
        "df_final['jaccard_score'] = df_final.apply(lambda x: jaccard(x.act_sel_text, x.pred_sel_text), axis=1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iD6IPCQFpbo",
        "outputId": "0e2dab37-80cc-4266-80cc-b2db0f651496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard accuracy is :  0.6108928058592357\n"
          ]
        }
      ],
      "source": [
        "jaccard_acc = df_final['jaccard_score'].mean()\n",
        "#print(df_final.head())\n",
        "print('Jaccard accuracy is : ', jaccard_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piA9c1omaaR5",
        "outputId": "96f88c12-2e97-4ba4-a098-38f553d338aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'd', 'have', 'responded', 'if', 'i', 'were', 'going']\n"
          ]
        }
      ],
      "source": [
        "#Test block for development\n",
        "\n",
        "find_indexes(train_df['clean_text_tokens'][0], train_df['clean_sel_text_tokens'][0], 'neutral')\n",
        "print(train_df['clean_text_tokens'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHhYyRbvaaD2",
        "outputId": "9e5d3ba3-9dbe-4521-9b19-f661b24afa11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V1_infer [-0.00823853  0.0125465  -0.05362745 -0.00804744 -0.03190618 -0.00868102\n",
            " -0.04342219  0.04068456  0.02885487 -0.00139011 -0.0370013   0.01534083\n",
            " -0.0025305  -0.05201721  0.03253455 -0.0085752   0.02434799 -0.07629792\n",
            " -0.01320806  0.05194129 -0.03206015 -0.0479126   0.00537943  0.00213766\n",
            " -0.02185634 -0.09854241  0.00201005  0.02742022 -0.0083191   0.04130479\n",
            "  0.06971811 -0.0339016   0.01470919 -0.04786061  0.0945525  -0.01840335\n",
            "  0.03125513 -0.02065532 -0.02845261  0.0605186 ]\n",
            "[('24906', 0.7340426445007324), ('7594', 0.7134906053543091), ('19114', 0.6855695247650146), ('4375', 0.6833310127258301), ('24921', 0.6669832468032837), ('17490', 0.6641349196434021), ('23033', 0.6558976173400879), ('5369', 0.6542665362358093), ('1187', 0.6504262685775757), ('15201', 0.6486458778381348)]\n",
            "[-2.5872064  -0.08458285 -2.4285684  -0.7263068  -1.7792158  -0.64430296\n",
            " -1.2457631  -2.4194722   0.70136184  2.796983    0.24344538  2.8644936\n",
            " -0.9671128  -3.1667988  -2.7575698   1.5393171  -1.148592   -3.2574675\n",
            "  1.7135544   4.0748086  -1.6714553   0.3119937  -0.6538483  -0.06155906\n",
            "  1.7256423  -2.7493672  -1.5955626   2.9895155  -1.5367565   0.16397834\n",
            "  0.42244464  1.4906183  -0.27332482 -0.17768995  1.0770655   2.0246856\n",
            "  0.18192558  1.8531133  -0.1606409   3.1313994 ]\n"
          ]
        }
      ],
      "source": [
        "# Doc2Vec Testing\n",
        "\n",
        "#to find the vector of a document which is not in training data\n",
        "test_data = word_tokenize(\"I love chatbots\".lower())\n",
        "v1 = modeld2v.infer_vector(test_data)\n",
        "print(\"V1_infer\", v1)\n",
        "\n",
        "# to find most similar doc using tags\n",
        "similar_doc = modeld2v.docvecs.most_similar('1')\n",
        "print(similar_doc)\n",
        "\n",
        "\n",
        "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
        "print(modeld2v.docvecs['1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwUvNl6DaZu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f2c164-4d30-4e8c-9428-6c2f0bbc05a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Love', 'You']"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "tokens = ['I', 'Love', 'You', 'Baby', '!']\n",
        "sel = ['Love', 'You']\n",
        "len(sel)\n",
        "\n",
        "start_tok=1\n",
        "end_tok = start_tok+ len(sel)\n",
        "end_tok\n",
        "\n",
        "tokens[start_tok: end_tok]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Tweet_Sentiment_Extraction_XGB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}